{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6faf1129",
   "metadata": {},
   "source": [
    "# Recreation de la question 3 du devoir 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fb2c31",
   "metadata": {},
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4c68662",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickletools import optimize\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision\n",
    "import torch.utils.data\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.optim as optim\n",
    "torch.manual_seed(6307)\n",
    "\n",
    "from inspect import _void\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from random import random as rand\n",
    "import math\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fbd5bb",
   "metadata": {},
   "source": [
    "## Donnees de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "571b988a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.Resize((224, 224)),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=28,\n",
    "                                          shuffle=True)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=28,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd92ca30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_rounding_t(x): \n",
    "    r = torch.rand(x.shape)\n",
    "    r = r.to(device)\n",
    "    d = 1-(x % 1)\n",
    "    k1 = r > d\n",
    "    k2 = k1 == False\n",
    "    upper = torch.ceil(x*k1)\n",
    "    lower = torch.floor(x*k2)\n",
    "    x_int = upper+lower\n",
    "    return x_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91c22821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quntize_block(x, s, z, b, stochastic=False):\n",
    "    c = (2**b)-1\n",
    "    xc = torch.zeros(x.shape)\n",
    "    if(stochastic):\n",
    "        x_int = stochastic_rounding_t((x/s)+z)\n",
    "        x_int[x_int<0]=0\n",
    "        x_int[x_int>c]=c\n",
    "        x_hat = s*(x_int-z)\n",
    "    else:  \n",
    "        x_int = (x/s)\n",
    "        x_int = torch.round(x_int)+z\n",
    "        x_int[x_int<0]=0\n",
    "        x_int[x_int>c]=c\n",
    "        x_hat = s*(x_int-z)\n",
    "    return x_hat\n",
    "\n",
    "def ACIQ(param, bit):\n",
    "    ex = torch.mean(param)\n",
    "    b = param - ex\n",
    "    b = torch.abs(b)\n",
    "    b = torch.mean(b)\n",
    "    if(bit == 2):\n",
    "        a = 2.83*b\n",
    "    elif(bit == 3):\n",
    "        a = 3.86*b\n",
    "    elif(bit == 4):\n",
    "        a = 5.03*b\n",
    "    else:\n",
    "        raise Exception(\"Seul les encodages à 2,3 ou 4 bits sont supportés\")\n",
    "    return a.item()\n",
    "\n",
    "def MSE(x,x_hat):\n",
    "    soustraction = x-x_hat\n",
    "    carre = torch.square(soustraction)\n",
    "    mse = torch.mean(carre)\n",
    "    return mse.item()\n",
    "\n",
    "def szfinder(q_min, q_max, b):\n",
    "    s = (q_max-q_min)/((2**b)-1)\n",
    "    #if(s==0):\n",
    "        #s = 0.001\n",
    "    z = (-q_min)/s\n",
    "    return s,z\n",
    "\n",
    "def bruteForceOptim(x, b, step):\n",
    "    q_min = torch.min(x)\n",
    "    q_max = torch.max(x)\n",
    "    q_min = q_min.item()\n",
    "    q_max = q_max.item()\n",
    "    mse_min = np.array([np.inf, q_min])\n",
    "    mse_max =np.array([np.inf, q_max])\n",
    "    stop = torch.mean(x)\n",
    "    stop = stop.item()\n",
    "    while(q_max >= stop):\n",
    "        s, z = szfinder(q_min, q_max, b)\n",
    "        x_hat = quntize_block(x, s, z, b, stochastic=False)\n",
    "        mse_t = MSE(x,x_hat)\n",
    "        if(mse_t < mse_max[0]):\n",
    "            mse_max[0] = mse_t\n",
    "            mse_max[1] = q_max\n",
    "        q_max -= step\n",
    "    while(q_min <= x.mean()):\n",
    "        s, z = szfinder(q_min, q_max, b)\n",
    "        x_hat = quntize_block(x, s, z, b, stochastic=False)\n",
    "        mse_t = MSE(x,x_hat)\n",
    "        if(mse_t < mse_max[0]):\n",
    "            mse_min[0] = mse_t\n",
    "            mse_min[1] = q_max\n",
    "        q_min += step\n",
    "    return mse_min[1], mse_max[1]\n",
    "\n",
    "def clipping_range(x,bit, step, method=\"min_max\"):\n",
    "    if(method==\"ACIQ\"):\n",
    "        a = ACIQ(x, bit)\n",
    "        q_min = -a\n",
    "        q_max = a\n",
    "    \n",
    "    elif(method == \"heuristic\"):\n",
    "        q_min, q_max = bruteForceOptim(x, bit, step)\n",
    "    else:\n",
    "        q_min = torch.min(x)\n",
    "        q_max = torch.max(x)\n",
    "        q_min = q_min.item()\n",
    "        q_max = q_max.item()\n",
    "    return q_min,q_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a4d7dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibration(model,device, calibration_loader=torch.utils.data.dataloader.DataLoader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      bit = 3\n",
    "      q = np.array([[0,0],[0,0],[0,0]])\n",
    "      quantization = [False, False]\n",
    "      methode = \"min_max\"\n",
    "      for batch_idx, (x, y) in enumerate(calibration_loader):\n",
    "        x = x.to(device=device)\n",
    "        y = y.to(device=device)\n",
    "        scores, a1, a2, a3 = model(x, bit, quantization, methode, q )\n",
    "      return a1, a2, a3\n",
    "\n",
    "def weight_quantization(param, bit, clipping_method, filter_wise=False):\n",
    "    param_hat = torch.zeros_like(param)\n",
    "    if(filter_wise):\n",
    "        param_hat = torch.ones(param.shape)\n",
    "        for i in range(param.shape[0]):\n",
    "            x = param[i]\n",
    "            q_min, q_max = clipping_range(x,bit,0.1, clipping_method)\n",
    "            s,z = szfinder(q_min,q_max,bit)\n",
    "            if(s == 0):\n",
    "                s = 0.01\n",
    "            param_hat[i] = quntize_block(x, s, z, bit, stochastic=False)\n",
    "            \n",
    "    else:\n",
    "        q_min, q_max = clipping_range(param,bit,0.1, clipping_method)\n",
    "        s,z = szfinder(q_min,q_max,bit)\n",
    "        param_hat = quntize_block(param, s, z, bit, stochastic=False)\n",
    "    return param_hat\n",
    "\n",
    "def npoids(x, bit,methode=\"min_max\", filter_wise = False):\n",
    "    with torch.no_grad():\n",
    "        k1 = weight_quantization(x, bit, methode, filter_wise)\n",
    "        k1 = k1.to(device)\n",
    "        x1 = nn.Parameter(k1)\n",
    "        x = x1\n",
    "        return x\n",
    "\n",
    "\n",
    "def activation_quantization(activation, bit, q_min, q_max, filter_wise=False):\n",
    "    activation_hat = torch.zeros_like(activation)\n",
    "    if(filter_wise):\n",
    "        activation_hat = torch.ones(activation.shape)\n",
    "        for i in range(activation.shape[0]):\n",
    "            s,z = szfinder(q_min,q_max,bit)\n",
    "            activation_hat = quntize_block(activation, s, z, bit, stochastic=False)\n",
    "    else:\n",
    "        s,z = szfinder(q_min,q_max,bit)\n",
    "\n",
    "        activation_hat = quntize_block(activation, s, z, bit, stochastic=False)\n",
    "    return activation_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3531e1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLinear(nn.Linear):\n",
    "    #def __init__(self, in_features, out_features,q_min, q_max, bit, methode=\"min_max\"  ,quantization = [False, False], bias=True,\n",
    "                 #w_qmodule=nn.Identity(), act_qmodule=nn.Identity()\n",
    "                 #):\n",
    "    def __init__(self, in_features, out_features,q_min, q_max, bias=True,\n",
    "                 w_qmodule=nn.Identity(), act_qmodule=nn.Identity()\n",
    "                 ):\n",
    "        super(QLinear, self).__init__(in_features, out_features, bias)\n",
    "        self.w_quant = w_qmodule\n",
    "        self.act_quant = act_qmodule\n",
    "        self.q_min = q_min\n",
    "        self.q_max = q_max\n",
    "\n",
    "    def forward(self, input, bit, quantization, methode, q_min, q_max, filter):\n",
    "      #TODO\n",
    "      self.quantization = quantization\n",
    "      self.q_min = q_min\n",
    "      self.q_max = q_max\n",
    "      # Quantize the weight\n",
    "      weight_q = self.weight\n",
    "      input_q = input\n",
    "      if(not self.training):\n",
    "        if(self.quantization[0]):\n",
    "          weight_q = npoids(weight_q, bit,methode,True)\n",
    "          self.weight = weight_q\n",
    "        if(self.quantization[1]):\n",
    "          input_q = activation_quantization(input, bit, self.q_min, self.q_max, filter_wise=filter)\n",
    "\n",
    "        # Quantize the Activation\n",
    "      output = F.linear(input_q, weight_q, self.bias)\n",
    "\n",
    "      return output\n",
    "    \n",
    "class QConv2d(nn.Conv2d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, q_min, q_max, \n",
    "                 stride=1, padding=0, dilation=1, groups=1, bias=True,\n",
    "                 w_qmodule=nn.Identity(), act_qmodule=nn.Identity()\n",
    "                 ):\n",
    "        super(QConv2d, self).__init__(\n",
    "            in_channels, out_channels, kernel_size, stride, padding, dilation,\n",
    "            groups, bias)\n",
    "\n",
    "        self.w_quant = w_qmodule\n",
    "        self.act_quant = act_qmodule\n",
    "        self.q_min = q_min\n",
    "        self.q_max = q_max\n",
    "\n",
    "    def forward(self, input,bit, quantization, methode, q_min, q_max, filter):\n",
    "        self.quantization = quantization\n",
    "        self.q_min = q_min\n",
    "        self.q_max = q_max\n",
    "\n",
    "\n",
    "        #TODO\n",
    "        # Quantize the weight\n",
    "        weight_q = self.weight\n",
    "        input_q = input\n",
    "        if(not self.training):\n",
    "          if(self.quantization[0]):\n",
    "            weight_q = npoids(weight_q, bit,methode,True)\n",
    "            self.weight = weight_q\n",
    "          if(self.quantization[1]):\n",
    "            input_q = activation_quantization(input, bit, self.q_min, self.q_max, filter_wise=filter).to(device)\n",
    "            #print(input_q)\n",
    "        # Quantize the Activation\n",
    "        \n",
    "\n",
    "        output = F.conv2d(input_q, weight_q, self.bias, self.stride, self.padding, self.dilation, self.groups)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "97e234d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Quantized_VGG(nn.Module):\n",
    "    def __init__(self, w_bit, clipping_method, filter_wise):\n",
    "        super(Quantized_VGG, self).__init__()\n",
    "        \n",
    "        self.w_bit = w_bit\n",
    "        self.clipping_method = clipping_method\n",
    "        self.filter_wise = filter_wise\n",
    "        self.stochastic = False\n",
    "        \n",
    "        self.conv1_1 = QConv2d(in_channels=3, out_channels=64, kernel_size=3,q_min = -1, q_max = 1, padding=1)\n",
    "        self.conv1_2 = QConv2d(in_channels=64, out_channels=64, kernel_size=3,q_min = -1, q_max = 1, padding=1)\n",
    "\n",
    "        self.conv2_1 = QConv2d(in_channels=64, out_channels=128, kernel_size=3,q_min = -1, q_max = 1, padding=1)\n",
    "        self.conv2_2 = QConv2d(in_channels=128, out_channels=128, kernel_size=3,q_min = -1, q_max = 1, padding=1)\n",
    "\n",
    "        self.conv3_1 = QConv2d(in_channels=128, out_channels=256, kernel_size=3,q_min = -1, q_max = 1, padding=1)\n",
    "        self.conv3_2 = QConv2d(in_channels=256, out_channels=256, kernel_size=3,q_min = -1, q_max = 1, padding=1)\n",
    "        self.conv3_3 = QConv2d(in_channels=256, out_channels=256, kernel_size=3,q_min = -1, q_max = 1, padding=1)\n",
    "\n",
    "        self.conv4_1 = QConv2d(in_channels=256, out_channels=512, kernel_size=3,q_min = -1, q_max = 1, padding=1)\n",
    "        self.conv4_2 = QConv2d(in_channels=512, out_channels=512, kernel_size=3,q_min = -1, q_max = 1, padding=1)\n",
    "        self.conv4_3 = QConv2d(in_channels=512, out_channels=512, kernel_size=3,q_min = -1, q_max = 1, padding=1)\n",
    "\n",
    "        self.conv5_1 = QConv2d(in_channels=512, out_channels=512, kernel_size=3,q_min = -1, q_max = 1, padding=1)\n",
    "        self.conv5_2 = QConv2d(in_channels=512, out_channels=512, kernel_size=3,q_min = -1, q_max = 1, padding=1)\n",
    "        self.conv5_3 = QConv2d(in_channels=512, out_channels=512, kernel_size=3,q_min = -1, q_max = 1, padding=1)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.fc1 = QLinear(25088, 4096,q_min = -1, q_max = 1)\n",
    "        self.fc2 = QLinear(4096, 4096, q_min = -1, q_max = 1)\n",
    "        self.fc3 = QLinear(4096, 10,q_min = -1, q_max = 1)\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=1e-4, weight_decay=5e-7)\n",
    "\n",
    "    \n",
    "    def forward(self, x, bit, quantization, methode, filter = False):\n",
    "        \n",
    "        x = F.relu(self.conv1_1(x, bit[0], quantization = [quantization[0], False], methode=methode,  q_min = -1,q_max =  1,filter = filter))\n",
    "        x = F.relu(self.conv1_2(x, bit[1], quantization = [quantization[1], False], methode=methode,  q_min = -1,q_max =  1,filter = filter))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv2_1(x, bit[2], quantization = [quantization[2], False], methode=methode,  q_min = -1,q_max =  1,filter = filter))\n",
    "        x = F.relu(self.conv2_2(x, bit[3], quantization = [quantization[3], False], methode=methode,  q_min = -1,q_max =  1,filter = filter))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv3_1(x, bit[4], quantization = [quantization[4], False], methode=methode,  q_min = -1,q_max =  1,filter = filter))\n",
    "        x = F.relu(self.conv3_2(x, bit[5], quantization = [quantization[5], False], methode=methode,  q_min = -1,q_max =  1,filter = filter))\n",
    "        x = F.relu(self.conv3_3(x, bit[6], quantization = [quantization[6], False], methode=methode,  q_min = -1,q_max =  1,filter = filter))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv4_1(x, bit[7], quantization = [quantization[7], False], methode=methode,  q_min = -1,q_max =  1,filter = filter))\n",
    "        x = F.relu(self.conv4_2(x, bit[8], quantization = [quantization[8], False], methode=methode,  q_min = -1,q_max =  1,filter = filter))\n",
    "        x = F.relu(self.conv4_3(x, bit[9], quantization = [quantization[9], False], methode=methode,  q_min = -1,q_max =  1,filter = filter))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv5_1(x, bit[10], quantization = [quantization[10], False], methode=methode,  q_min = -1,q_max =  1,filter = filter))\n",
    "        x = F.relu(self.conv5_2(x, bit[11], quantization = [quantization[11], False], methode=methode,  q_min = -1,q_max =  1,filter = filter))\n",
    "        x = F.relu(self.conv5_3(x, bit[12], quantization = [quantization[12], False], methode=methode,  q_min = -1,q_max =  1,filter = filter))\n",
    "        x = self.maxpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x, bit[13], quantization = [quantization[13], False], methode=methode,  q_min = -1,q_max = 1,filter = filter))\n",
    "        x = F.relu(self.fc2(x, bit[14], quantization = [quantization[14], False], methode=methode,  q_min = -1,q_max = 1,filter = filter))\n",
    "        out = self.fc3(x, bit[15], quantization = [quantization[15], False], methode=methode,  q_min = -1,q_max = 1,filter = filter)\n",
    "        \n",
    "        return out\n",
    "\n",
    "    \n",
    "    def fit(self, nb_epochs=5, trainloader=torch.utils.data.dataloader.DataLoader):\n",
    "        err_train = np.zeros(nb_epochs) \n",
    "        k = [32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32]\n",
    "        w = [False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False]\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        learning_rate = 0.001\n",
    "        optimizer = optim.Adam(self.parameters(), lr = learning_rate)\n",
    "        for i in range(nb_epochs):\n",
    "            for batch_idx, (data, targets) in enumerate(trainloader):\n",
    "                data = data.to(device=device)\n",
    "                targets = targets.to(device=device)\n",
    "                scores = self(data, k, w, \"min_max\", filter = False)\n",
    "                loss = criterion(scores, targets)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                err_train[i] = loss.data\n",
    "            print('Epoch:', i, 'Train loss = ',  err_train[i])\n",
    "\n",
    "    def test_acc(self,test_size, bit, quantization, methode, valloader=torch.utils.data.dataloader.DataLoader, filter = False):\n",
    "        self.filter = filter\n",
    "        num_correct = 0\n",
    "        num_samples = 0\n",
    "        self.quantization = quantization\n",
    "        self.bit = bit\n",
    "        self.methode = methode\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (x, y) in enumerate(valloader):\n",
    "                if(batch_idx % 10 == 0):\n",
    "                    a = batch_idx/len(valloader)\n",
    "                x = x.to(device=device)\n",
    "                y = y.to(device=device)\n",
    "                scores = self(x, self.bit, self.quantization, self.methode, self.filter)\n",
    "                _, predictions = scores.max(1)\n",
    "                num_correct += (predictions == y).sum()\n",
    "                num_samples += predictions.size(0)\n",
    "                if(batch_idx == test_size):\n",
    "                    break\n",
    "            self.train()\n",
    "            test = num_correct/num_samples*100\n",
    "        return test\n",
    "\n",
    "    def model_size(self, bit, quantization_map):\n",
    "        size = 0\n",
    "        i = 0\n",
    "        for idx, (name, param) in enumerate(self.named_parameters()):\n",
    "            if(idx % 2 == 0):\n",
    "                a = torch.prod(torch.tensor(param.shape))\n",
    "                if(quantization_map[i]):\n",
    "                    sizet = bit[i]*a\n",
    "                else:\n",
    "                    sizet = 32*a\n",
    "                i+=1 \n",
    "                size += sizet\n",
    "                \n",
    "        return size/(2**20) \n",
    "\n",
    "    def plot_weight_hist(self,quantization=False):\n",
    "        sns.set()\n",
    "        plt.figure(figsize=(6,4))\n",
    "        for i, p in  enumerate(self.named_parameters()):\n",
    "            name, param = p\n",
    "            w = param.cpu().detach().numpy().reshape(-1)\n",
    "            plt.title(\"Histogram of Weights\")\n",
    "            plt.hist(w, density=True, alpha=0.4)\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8af17d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "network = Quantized_VGG(w_bit = 8, clipping_method=\"min_max\", filter_wise=False)\n",
    "network.to(device)\n",
    "network.load_state_dict(torch.load(\"VGG16_CIFAR10\", map_location=torch.device(device)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c40990",
   "metadata": {},
   "source": [
    "Les fonctions qui suivent permettent de donner un score pondere aux results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8e56b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(mass_result, mass_weight, result, weight):\n",
    "    return mass_result*result+mass_weight*((1/weight)*1000)\n",
    "\n",
    "def random_bitmap(size):\n",
    "    bit = np.random.randint(2, size=(1, size))+3\n",
    "    quantization_map = np.random.randint(2, size=(1, size))\n",
    "    return bit[0], quantization_map[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad31a4b4",
   "metadata": {},
   "source": [
    "Ici, YAML_generator modifie le fichier d'architecture de Eyeriss pour mettre la valeur desiree. energy_compute_read permet de lire le fichier de output de mapper pour lire l'energie optimale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc670252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def YAML_generator(bit_width = 16, path=\"eyeriss_base.yaml\"):\n",
    "    width = 4*bit_width\n",
    "    with open(path,'r') as file:\n",
    "        txt = file.read()\n",
    "        txt_new = txt.replace('$bit_width$',str(bit_width))\n",
    "        txt_new = txt_new.replace('$m_width$',str(width))\n",
    "        txt_new = txt_new.replace('$m_width2$',str(bit_width))\n",
    "        with open('arch/eyeriss_like.yaml','w') as output:\n",
    "            output.write(txt_new)\n",
    "\n",
    "def energy_compute_read(path = \"timeloop-mapper.stats.txt\"):\n",
    "    with open(path) as f:\n",
    "        lines = f.readlines()\n",
    "    f.close\n",
    "    i = 0\n",
    "    for word in lines[len(lines)-2]:\n",
    "        i += 1\n",
    "        if word == \"=\":\n",
    "            break\n",
    "    s = float(lines[len(lines)-2][i:len(lines[len(lines)-2])-1])\n",
    "    return(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609610f3",
   "metadata": {},
   "source": [
    "get_score_energy permet de sortir la somme des energies de toutes les couches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a5abebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_energy(array = np.ones((1,16)), bit = np.ones((1,16))):\n",
    "    energy = 0\n",
    "    inarray = (array == 0)*16+(bit*array)\n",
    "    for v in range(1,14):\n",
    "        YAML_generator(inarray[v], path=\"eyeriss_base.yaml\")\n",
    "        mapper_command = f\"timeloop-mapper prob/VGG02_layer{v}.yaml \\\n",
    "                arch/components/*.yaml \\\n",
    "                arch/eyeriss_like.yaml \\\n",
    "                constraints/*.yaml     \\\n",
    "                mapper/mapper.yaml\" + \">/dev/null 2>&1\"\n",
    "        os.system(mapper_command)\n",
    "        x = energy_compute_read()\n",
    "        energy += x \n",
    "    return energy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a81230",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b8c4e5",
   "metadata": {},
   "source": [
    "Ici, une ponderation de 3 pour 1 en faveur de la consommation d'energie a ete implementee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "42b9014b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_219954/3836842984.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  resultats = np.array([-np.inf, bit, quantization_map, np.inf, np.inf, np.inf])\n",
      "  2%|█                                           | 1/40 [01:14<48:31, 74.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass: 83.7557601928711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██▏                                         | 2/40 [02:27<46:47, 73.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass: 72.58065032958984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███▎                                        | 3/40 [03:37<44:24, 72.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass: 72.23502349853516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▍                                       | 4/40 [05:37<54:30, 90.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(87.0968)\n",
      "tensor(128.3736)\n",
      "[3 3 3 3 4 3 4 3 3 4 3 4 3 4 4 4]\n",
      "[0 0 1 0 0 0 1 0 1 0 0 0 1 1 0 0]\n",
      "72.67999999999998\n",
      "tensor(87.0968)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████▌                                      | 5/40 [07:00<51:24, 88.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass: 83.52534484863281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████▌                                     | 6/40 [07:43<41:14, 72.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass: 84.67742156982422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████▋                                    | 7/40 [09:57<50:57, 92.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(86.4055)\n",
      "tensor(134.8317)\n",
      "[4 3 4 3 4 3 4 4 3 3 4 3 4 3 3 4]\n",
      "[1 0 0 1 0 0 1 1 1 0 0 1 1 1 1 0]\n",
      "61.949999999999996\n",
      "tensor(86.4055)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▊                                   | 8/40 [11:07<45:38, 85.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass: 83.64054870605469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████▉                                  | 9/40 [12:27<43:16, 83.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass: 72.8110580444336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████████▊                                | 10/40 [13:42<40:31, 81.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass: 80.18433380126953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|███████████▊                               | 11/40 [14:25<33:32, 69.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass: 83.41014099121094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|█████████████▉                             | 13/40 [17:33<36:32, 81.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass: 83.7557601928711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|████████████████▏                          | 15/40 [20:13<32:33, 78.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass: 72.23502349853516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 16/40 [22:18<36:57, 92.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(85.5991)\n",
      "tensor(146.5499)\n",
      "[3 4 4 4 3 4 3 4 4 3 3 3 4 4 4 4]\n",
      "[0 1 1 1 1 1 0 1 0 1 1 0 0 1 0 1]\n",
      "49.22\n",
      "tensor(85.5991)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|███████████████████▎                       | 18/40 [25:17<31:47, 86.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass: 71.31336212158203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 20/40 [28:52<31:48, 95.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass: 82.7188949584961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|██████████████████████▌                    | 21/40 [29:48<26:29, 83.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass: 84.9078369140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████▋                   | 22/40 [31:02<24:16, 80.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass: 84.44700622558594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|████████████████████████▋                  | 23/40 [32:29<23:22, 82.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass: 84.44700622558594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 24/40 [33:42<21:15, 79.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass: 82.94931030273438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████████████████████████▉                | 25/40 [34:42<18:26, 73.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass: 73.73271942138672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|█████████████████████████████              | 27/40 [36:59<14:55, 68.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass: 75.57603454589844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████████████████████████████▏           | 29/40 [40:34<15:53, 86.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass: 81.3364028930664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|████████████████████████████████▎          | 30/40 [41:17<12:14, 73.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass: 67.85713958740234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 32/40 [44:16<10:52, 81.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass: 70.27649688720703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|███████████████████████████████████▍       | 33/40 [45:39<09:33, 81.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass: 81.3364028930664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████████████████████████████████▌      | 34/40 [47:04<08:17, 82.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass: 81.91243743896484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|█████████████████████████████████████▋     | 35/40 [47:51<06:00, 72.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass: 61.4055290222168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 36/40 [48:46<04:28, 67.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass: 71.42857360839844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|███████████████████████████████████████▊   | 37/40 [50:08<03:33, 71.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass: 78.80184173583984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|████████████████████████████████████████▊  | 38/40 [51:32<02:30, 75.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass: 82.83409881591797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████████████████████████████████████▉ | 39/40 [53:05<01:20, 80.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass: 72.69585418701172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 40/40 [54:06<00:00, 81.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass: 84.9078369140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bit, quantization_map = random_bitmap(16)\n",
    "test_size = 30\n",
    "loop_size = 40\n",
    "mass_result = 1\n",
    "mass_weight = 3\n",
    "resultats = np.array([-np.inf, bit, quantization_map, np.inf, np.inf, np.inf])\n",
    "for i in tqdm(range(loop_size)):\n",
    "    network.load_state_dict(torch.load(\"VGG16_CIFAR10\", map_location=torch.device(device)))\n",
    "    result1 = network.test_acc(test_size, bit = bit, quantization = quantization_map, methode = \"min_max\", valloader = testloader) #Score acc\n",
    "    if result1 < 85:\n",
    "        weight = np.inf\n",
    "        print(f\"Pass: {result1}\")\n",
    "    else:\n",
    "        weight = get_score_energy(quantization_map, bit)\n",
    "    score = evaluation(mass_result, mass_weight, result1, weight)\n",
    "    if(result1 > 85 and score > resultats[0]):\n",
    "        resultats[0] = score\n",
    "        resultats[1] = bit\n",
    "        resultats[2] = quantization_map\n",
    "        resultats[3] = weight\n",
    "        resultats[4] = result1\n",
    "        print(result1)\n",
    "        print(resultats[0])\n",
    "        print(resultats[1])\n",
    "        print(resultats[2])\n",
    "        print(resultats[3])\n",
    "        print(resultats[4])\n",
    "    bit, quantization_map = random_bitmap(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e9866122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La meilleure combinaison trouvee est: [16  4  4  4  3  4 16  4 16  3  3 16 16  4 16  4]\n",
      "Cela donne une precision de 85.59907531738281 %\n",
      "La somme des energies par cycle de toutes les couches est: 49.22 pJ/Comput\n"
     ]
    }
   ],
   "source": [
    "inarray = (resultats[2] == 0)*16+(resultats[1]*resultats[2])\n",
    "print(f\"La meilleure combinaison trouvee est: {inarray}\")\n",
    "print(f\"Cela donne une precision de {resultats[4]} %\")\n",
    "print(f\"La somme des energies par cycle de toutes les couches est: {resultats[3]} pJ/Comput\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d56f8771",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_energy(array = np.ones((1,16)), bit = np.ones((1,16))):\n",
    "    energy = 0\n",
    "    list_energy = []\n",
    "    inarray = (array == 0)*16+(bit*array)\n",
    "    for v in range(1,14):\n",
    "        YAML_generator(inarray[v], path=\"eyeriss_base.yaml\")\n",
    "        mapper_command = f\"timeloop-mapper prob/VGG02_layer{v}.yaml \\\n",
    "                arch/components/*.yaml \\\n",
    "                arch/eyeriss_like.yaml \\\n",
    "                constraints/*.yaml     \\\n",
    "                mapper/mapper.yaml\" + \">/dev/null 2>&1\"\n",
    "        os.system(mapper_command)\n",
    "        x = energy_compute_read()\n",
    "        list_energy.append(x)   \n",
    "        print(v)\n",
    "        energy += x \n",
    "    return energy, list_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6014e59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = inarray\n",
    "q = resultats[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6d6223a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(49.22,\n",
       " [3.63, 2.51, 2.37, 2.16, 2.33, 5.76, 3.25, 5.97, 2.17, 2.55, 6.71, 6.71, 3.1])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_score_energy(q, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24be5fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
